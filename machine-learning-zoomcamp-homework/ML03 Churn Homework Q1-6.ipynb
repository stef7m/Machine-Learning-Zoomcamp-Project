{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e050d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ce173fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-11 13:01:26--  https://archive.ics.uci.edu/static/public/222/bank+marketing.zip\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified\n",
      "Saving to: 'bank+marketing.zip.2'\n",
      "\n",
      "bank+marketing.zip.     [    <=>             ] 999.85K  1.03MB/s    in 0.9s    \n",
      "\n",
      "2024-10-11 13:01:28 (1.03 MB/s) - 'bank+marketing.zip.2' saved [1023843]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/static/public/222/bank+marketing.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a6d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unziping file\n",
    "\n",
    "with zipfile.ZipFile('bank+marketing.zip.2', 'r') as zip_ref:\n",
    "    zip_ref.extractall('bank-marketing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3a9d558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bank.zip', 'bank-additional.zip']\n"
     ]
    }
   ],
   "source": [
    "# listing all files in the extracted folder to check name\n",
    "\n",
    "extracted_files = os.listdir('bank-marketing')\n",
    "print(extracted_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ebce9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip bank.zip\n",
    "with zipfile.ZipFile('bank-marketing/bank.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('bank-marketing')\n",
    "\n",
    "# Unzip bank-additional.zip\n",
    "with zipfile.ZipFile('bank-marketing/bank-additional.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('bank-marketing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "772d909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bank-names.txt', 'bank.csv', 'bank.zip', 'bank-additional', 'bank-full.csv', '__MACOSX', 'bank-additional.zip']\n"
     ]
    }
   ],
   "source": [
    "# Listing all files in the directory after unzipping\n",
    "extracted_files = os.listdir('bank-marketing')\n",
    "print(extracted_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a43b4db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset and checking first rows\n",
    "\n",
    "df = pd.read_csv('bank-marketing/bank-full.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8fced0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "job          object\n",
       "marital      object\n",
       "education    object\n",
       "default      object\n",
       "balance       int64\n",
       "housing      object\n",
       "loan         object\n",
       "contact      object\n",
       "day           int64\n",
       "month        object\n",
       "duration      int64\n",
       "campaign      int64\n",
       "pdays         int64\n",
       "previous      int64\n",
       "poutcome     object\n",
       "y            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the data tyeps\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6711f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to keep\n",
    "selected_columns = [\n",
    "    'age', 'job', 'marital', 'education', 'balance', \n",
    "    'housing', 'contact', 'day', 'month', 'duration', \n",
    "    'campaign', 'pdays', 'previous', 'poutcome', 'y'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56a1a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the specified columns\n",
    "df_selected = df[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c7d0d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          0\n",
       "job          0\n",
       "marital      0\n",
       "education    0\n",
       "balance      0\n",
       "housing      0\n",
       "contact      0\n",
       "day          0\n",
       "month        0\n",
       "duration     0\n",
       "campaign     0\n",
       "pdays        0\n",
       "previous     0\n",
       "poutcome     0\n",
       "y            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb35b5ca",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column education?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec2e2b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'secondary'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the most frequent observation (mode) for the 'education' column\n",
    "df_selected['education'].mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb3de0d",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "Create the correlation matrix for the numerical features of your dataset. In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "\n",
    "What are the two features that have the biggest correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f454d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the numerical features\n",
    "numerical_features = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7a2fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "correlation_matrix = df_selected[numerical_features].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da29e965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               age   balance       day  duration  campaign     pdays  previous\n",
      "age       1.000000  0.097783 -0.009120 -0.004648  0.004760 -0.023758  0.001288\n",
      "balance   0.097783  1.000000  0.004503  0.021560 -0.014578  0.003435  0.016674\n",
      "day      -0.009120  0.004503  1.000000 -0.030206  0.162490 -0.093044 -0.051710\n",
      "duration -0.004648  0.021560 -0.030206  1.000000 -0.084570 -0.001565  0.001203\n",
      "campaign  0.004760 -0.014578  0.162490 -0.084570  1.000000 -0.088628 -0.032855\n",
      "pdays    -0.023758  0.003435 -0.093044 -0.001565 -0.088628  1.000000  0.454820\n",
      "previous  0.001288  0.016674 -0.051710  0.001203 -0.032855  0.454820  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Display the correlation matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "666b71b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the pair of features with the highest correlation (excluding self-correlation)\n",
    "corr_pairs = correlation_matrix.unstack().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "097ebdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude self-correlation (correlation of 1)\n",
    "corr_pairs = corr_pairs[corr_pairs < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fde54894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two features with the highest correlation are: ('previous', 'pdays')\n"
     ]
    }
   ],
   "source": [
    "# Get the pair with the highest correlation\n",
    "highest_corr = corr_pairs.idxmax()\n",
    "print(\"The two features with the highest correlation are:\", highest_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc3110a",
   "metadata": {},
   "source": [
    "# Target encoding\n",
    "\n",
    "Now we want to encode the y variable.\n",
    "Let's replace the values yes/no with 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee5f5cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k8/6mb93rb95jd6bknf4qsf29_r0000gn/T/ipykernel_42108/4103376218.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['y'] = df_selected['y'].replace({'yes': 1, 'no': 0})\n"
     ]
    }
   ],
   "source": [
    "# Encode the 'y' variable: replace 'yes' with 1 and 'no' with 0\n",
    "df_selected['y'] = df_selected['y'].replace({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "089cc14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verify the changes\n",
    "print(df_selected['y'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfc0c8a",
   "metadata": {},
   "source": [
    "# Split the data\n",
    "\n",
    "Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "Use Scikit-Learn for that (the train_test_split function) and set the seed to 42.\n",
    "Make sure that the target value y is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b8ecba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b24e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features and target\n",
    "X = df_selected.drop(columns=['y'])  # Features\n",
    "y = df_selected['y']                 # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb46ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a4d4cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: 60% training and 40% temporary (validation + test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e7a4eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second split: 20% validation and 20% test (from the 40% temporary set)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12a36033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (27126, 14)\n",
      "Validation set size: (9042, 14)\n",
      "Test set size: (9043, 14)\n"
     ]
    }
   ],
   "source": [
    "# Check the size of the splits\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Validation set size:\", X_val.shape)\n",
    "print(\"Test set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4505fbb1",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Calculate the mutual information score between y and other categorical variables in the dataset. Use the training set only.\n",
    "Round the scores to 2 decimals using round(score, 2).\n",
    "Which of these variables has the biggest mutual information score?\n",
    "\n",
    "- contact\n",
    "- education\n",
    "- housing\n",
    "- poutcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97dd5051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75f87a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical features\n",
    "categorical_features = ['contact', 'education', 'housing', 'poutcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58acfbd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k8/6mb93rb95jd6bknf4qsf29_r0000gn/T/ipykernel_42108/3452341006.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate mutual information scores for categorical features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmi_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutual_info_classif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscrete_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36mmutual_info_classif\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    462\u001b[0m     \"\"\"\n\u001b[1;32m    463\u001b[0m     \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_estimate_mi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscrete_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[0;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    254\u001b[0m            \u001b[0mData\u001b[0m \u001b[0mSets\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPLoS\u001b[0m \u001b[0mONE\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2014.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \"\"\"\n\u001b[0;32m--> 256\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mdiscrete_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m     \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m     def __array_wrap__(\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'unknown'"
     ]
    }
   ],
   "source": [
    "# Calculate mutual information scores for categorical features\n",
    "mi_scores = mutual_info_classif(X_train[categorical_features], y_train, discrete_features=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe40f8",
   "metadata": {},
   "source": [
    "### I got this error since the mutual_info_classif function requires numerical data, and the categorical features are still in string format. To resolve this, I need to encode the categorical variables before calculating the mutual information score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca266fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1543f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "encoded_X_train = X_train[categorical_features].apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f326b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mutual information scores for the encoded categorical features\n",
    "mi_scores = mutual_info_classif(encoded_X_train, y_train, discrete_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b879a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the scores to 2 decimals\n",
    "mi_scores = [round(score, 2) for score in mi_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a1558bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to pair feature names with their mutual information scores\n",
    "mi_scores_dict = dict(zip(categorical_features, mi_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17a64055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information Scores:\n",
      "contact: 0.01\n",
      "education: 0.0\n",
      "housing: 0.01\n",
      "poutcome: 0.03\n"
     ]
    }
   ],
   "source": [
    "# Print the mutual information scores\n",
    "print(\"Mutual Information Scores:\")\n",
    "for feature, score in mi_scores_dict.items():\n",
    "    print(f\"{feature}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a38ee42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The variable with the biggest mutual information score is: poutcome\n"
     ]
    }
   ],
   "source": [
    "# Find the feature with the highest mutual information score\n",
    "most_informative_feature = max(mi_scores_dict, key=mi_scores_dict.get)\n",
    "print(\"\\nThe variable with the biggest mutual information score is:\", most_informative_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f32408d",
   "metadata": {},
   "source": [
    "Question 4\n",
    "\n",
    "- Now let's train a logistic regression.\n",
    "- Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "- Fit the model on the training dataset.\n",
    "- To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "- Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "- What accuracy did you get?\n",
    "\n",
    "- 0.6\n",
    "- 0.7\n",
    "- 0.8\n",
    "- 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1370df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3bcbee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: One-hot encoding for categorical features\n",
    "categorical_features = ['job', 'marital', 'education', 'housing', 'contact', 'month', 'poutcome']\n",
    "numerical_features = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a166089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessor: one-hot encode categorical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep the numerical features as they are\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8763e0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create the logistic regression pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "edf4bc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('cat', OneHotEncoder(),\n",
       "                                                  ['job', 'marital',\n",
       "                                                   'education', 'housing',\n",
       "                                                   'contact', 'month',\n",
       "                                                   'poutcome'])])),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(max_iter=1000, random_state=42,\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae121072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Make predictions on the validation set\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80684fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Calculate the accuracy on the validation dataset\n",
    "accuracy = accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec9e8dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation set: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Round the accuracy to 2 decimal places\n",
    "accuracy = round(accuracy, 2)\n",
    "print(\"Accuracy on the validation set:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138a448f",
   "metadata": {},
   "source": [
    "Question 5\n",
    "\n",
    "- Let's find the least useful feature using the feature elimination technique.\n",
    "- Train a model with all these features (using the same parameters as in Q4).\n",
    "- Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "- For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "- Which of following feature has the smallest difference?\n",
    "\n",
    "- age\n",
    "- balance\n",
    "- marital\n",
    "- previous\n",
    "\n",
    "Note: The difference doesn't have to be positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18304c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Train the model with all features and get the original accuracy\n",
    "original_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0157e8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('cat', OneHotEncoder(),\n",
       "                                                  ['job', 'marital',\n",
       "                                                   'education', 'housing',\n",
       "                                                   'contact', 'month',\n",
       "                                                   'poutcome'])])),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(max_iter=1000, random_state=42,\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model on the training data\n",
    "original_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "529c2480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the original accuracy on the validation set\n",
    "original_accuracy = accuracy_score(y_val, original_model.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3fa11684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize a dictionary to store accuracy differences for each feature\n",
    "accuracy_differences = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f6342e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Evaluate the model excluding each feature one by one\n",
    "for feature in X_train.columns:\n",
    "    # Exclude the current feature\n",
    "    X_train_excluded = X_train.drop(columns=[feature])\n",
    "    X_val_excluded = X_val.drop(columns=[feature])\n",
    "    \n",
    "    # Update the preprocessor to fit only the remaining features\n",
    "    temp_preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(), [col for col in categorical_features if col != feature])\n",
    "        ],\n",
    "        remainder='passthrough'  # Keep the numerical features as they are, except the excluded one\n",
    "    )\n",
    "    \n",
    "    # Train a new model without the current feature\n",
    "    model_excluded = Pipeline(steps=[\n",
    "        ('preprocessor', temp_preprocessor),\n",
    "        ('classifier', LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Fit the model on the training data with the excluded feature\n",
    "    model_excluded.fit(X_train_excluded, y_train)\n",
    "    \n",
    "    # Calculate the accuracy without the feature\n",
    "    accuracy_without_feature = accuracy_score(y_val, model_excluded.predict(X_val_excluded))\n",
    "    \n",
    "    # Calculate the difference from the original accuracy\n",
    "    accuracy_difference = original_accuracy - accuracy_without_feature\n",
    "    accuracy_differences[feature] = round(accuracy_difference, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a3f4d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Find the feature with the smallest difference\n",
    "least_useful_feature = min(accuracy_differences, key=accuracy_differences.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3de7c6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences in accuracy without each feature: {'age': 0.0, 'job': 0.0, 'marital': -0.0, 'education': 0.0, 'balance': 0.0, 'housing': -0.0, 'contact': 0.0, 'day': -0.0, 'month': -0.0, 'duration': 0.01, 'campaign': 0.0, 'pdays': 0.0, 'previous': 0.0, 'poutcome': 0.01}\n",
      "\n",
      "The feature with the smallest difference is: age\n"
     ]
    }
   ],
   "source": [
    "print(\"Differences in accuracy without each feature:\", accuracy_differences)\n",
    "print(\"\\nThe feature with the smallest difference is:\", least_useful_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2439e65e",
   "metadata": {},
   "source": [
    "Question 6\n",
    "\n",
    "- Now let's train a regularized logistic regression.\n",
    "- Let's try the following values of the parameter C: [0.01, 0.1, 1, 10, 100].\n",
    "- Train models using all the features as in Q4.\n",
    "- Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "- Which of these C leads to the best accuracy on the validation set?\n",
    "\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- 10\n",
    "- 100\n",
    "\n",
    "Note: If there are multiple options, select the smallest C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aaa15e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of C values to try\n",
    "C_values = [0.01, 0.1, 1, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "925af10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store accuracies for each C\n",
    "accuracy_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2633ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Train and evaluate models for each C value\n",
    "for C in C_values:\n",
    "    # Create a logistic regression model with the current C value\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate the accuracy on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    \n",
    "    # Round the accuracy to 3 decimal places\n",
    "    accuracy_rounded = round(accuracy, 3)\n",
    "    \n",
    "    # Store the accuracy in the dictionary\n",
    "    accuracy_scores[C] = accuracy_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "15c74c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Find the C value with the best accuracy\n",
    "best_C = max(accuracy_scores, key=accuracy_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ff769299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If multiple C values have the same accuracy, choose the smallest one\n",
    "best_C = min([c for c in accuracy_scores if accuracy_scores[c] == accuracy_scores[best_C]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "148c216d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies for each C value: {0.01: 0.899, 0.1: 0.9, 1: 0.901, 10: 0.901, 100: 0.901}\n",
      "\n",
      "The best C value is: 1\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(\"Accuracies for each C value:\", accuracy_scores)\n",
    "print(\"\\nThe best C value is:\", best_C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
